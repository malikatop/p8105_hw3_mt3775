---
title: "Homework 3"
author: "Malika Top"
date: "2024-10-14"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(ggridges)
```

### Problem 1
```{r load_noaa}
library(p8105.datasets)
data("ny_noaa")
dim(ny_noaa)
summary(ny_noaa)
```
The `ny_noaa` dataframe contains core information for all New York state stations
from the National Oceanic and Atmospheric Association (NOAA)'s database. It is 
a rather massive dataframe with  `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` 
columns. The key variables are:

* `date`: the date of observation
* `prcp`: rain precipitation levels (in tenths of mm)
* `snow`: snowfall levels (in mm)
* `swd`: snow depth (in mm)
* `tmax`: maximum temperature (tenths of degrees C)
* `tmin`: minimum temperature (tenths of degrees C)

There is a significant chunk of values missing from this dataframe and looking
at the `summary` command, there are 145,838 NA values for `prcp`, 381,221 NA 
values for `snow`, and 591,786 for `snowd`. In a dataframe with 
2,595,176 total rows, we might not be concerned too much for `prcp` but 
definitely for `snowd`. 

#### Data Cleaning
```{r clean_noaa}
cleaned_noaa = 
  ny_noaa |> 
  mutate(
    date = as.Date(date),
    month = month(date),
    day = day(date),
    year = year(date),
    tmin = as.integer(tmin) / 10,
    tmax = as.integer(tmax) / 10,
    prcp = as.integer(prcp) / 10
  )
```
In the description of this data, it is listed that the weather variables are
listed as having units that are in tenths of degrees Celsius or millimeters. 
That means that in cleaning this data, we have to divide the degrees by 10
to get the actual temperature. Assuming the same pattern for `prcp`, we 
also divide by 10. `snow` and `snowd` appear to be in correct units. Additionally,
I converted the `date` variable to be a DateTime object to more easily extract 
the `month`, `day`, `year` columns. 

#### Common Snowfall Measurements
```{r common_snow}
head(
  cleaned_noaa |> 
  group_by(snow) |> 
  summarise(n_obs = n())
)
```
**The most commonly observed value for snowfall was 0 mm.**

#### Average Max. Temperatures
```{r max_temp_jan_jul}
month_levels = c(`1` = "January", `7` = "July")
avg_max_01_07_plot = 
  cleaned_noaa |> 
  filter(month == 1 | month == 7) |> 
  group_by(id, month, year) |> 
  summarise(avg_max = mean(tmax)) |> 
  ggplot(aes(x = year, y = avg_max)) + 
  geom_line(size=0.5, alpha=0.5) +
  facet_grid(~month, labeller = as_labeller(month_levels)) +
  labs(
    x = "Year",
    y = "Average Max Temperature (C)"
  ) + 
  ggtitle("Average Max Temperature in NY in Jan vs Jul
          Across Years") + 
  theme_update(plot.title = element_text(hjust = 0.5)) +
  viridis::scale_color_viridis(
    discrete = TRUE
  )
avg_max_01_07_plot
```

We see that the average maximum temperature in July is considerably higher than 
in January which makes sense since summer is hotter than winter. Over time 
though, the temperatures oscillate back and forth with no consistent pattern
as one might expect with climate change, although July weather in 2010 looks
the highest. There are some particularly cool January's, such as in the early
1980s, and a particularly cool July in the late 1980s. 

#### tmax vs. tmin
```{r more_plots, fig.height = 4, fig.width = 10}
tmax_v_tmin = 
  ggplot(cleaned_noaa, aes(x = tmax, y = tmin)) + 
  geom_hex() +
  ggtitle("Maximum vs. Minimum Temperature in NY
          from 1981-2010") + 
  scale_fill_viridis_c()


options(repr.plot.width =9, repr.plot.height = 15) 
snowfall_dist_plot =
  cleaned_noaa |> 
  filter(snow > 0 & snow < 100) |> 
  na.omit() |> 
  group_by(year) |> 
  ggplot(aes(x = snow, y = factor(year))) +
  geom_density_ridges(scale = .85) +
  labs(
    x = "Snowfall (mm)",
    y = "Year"
  ) +
  ggtitle("Distribution of Snowfall from 1981-2010")

library(patchwork)
tmax_v_tmin + snowfall_dist_plot 
  
```

Looking at the hexplot of `tmax` vs `tmin` for the full dataset, the most
common maximum temperatures are between 0 and 30 degrees Celsius and 0 to 30
for the minimum temperature as well. As for snowfall, with so many years, it
is a bit difficult to discern, but the amount of snowfall seems to be 
fairly consistent - data including 2020 onwards would probably be quite
different though. 

### Problem 2

#### Loading Data
```{r load_accelerometer}
# KEY: 1 = male, 2 = female, education = 1 = less than high school, 2 = high 
# school, 3 = more than high school
accel_demo_df = read.csv("data/nhanes_covar.csv", skip = 4) |> 
  janitor::clean_names()
accel_meter_df = read.csv("data/nhanes_accel.csv") |> 
  janitor::clean_names()
```
#### Tidying Data
```{r tidy_accelerometer}
accel_meter_tidy = 
  accel_meter_df |> 
  pivot_longer(
    min1:min1440,
    names_to = "minute",
    names_prefix = "min",
    values_to = "mims_val"
  )
```
#### Merging and further cleaning
```{r merge_and_clean_data}
education_levels = c(
  `1`= "Less than high school",
  `2` = "High school equivalent",
  `3` = "More than high school"
)
accel_comb = 
  left_join(accel_meter_tidy, accel_demo_df, by = "seqn") |> 
  filter(age >= 21) |> 
  na.omit() |> 
  mutate(
    education = case_match(
      education, 
      1 ~ "Less than high school",
      2 ~ "High school equivalent", 
      3 ~ "More than high school"
    ),
    education = as.factor(education),
    sex = case_match(
      sex,
      1 ~ "male",
      2 ~ "female"
    ),
    sex = as.factor(sex),
    minute = as.integer(minute)
  )
```
##### Gender, Education, and Age 
```{r age_sex_education}
gender_educ =
  accel_comb |> 
  distinct(seqn, .keep_all = TRUE) |>
  group_by(education, sex) |>
  summarize(
    count = n_distinct(seqn)
  ) |> 
  pivot_wider(
    names_from = "sex",
    values_from = "count"
  ) 
gender_educ_table = 
  gender_educ |> 
  knitr::kable()
gender_educ_table
```

Looking at the table for the number of men and women in each education category,
gender is split pretty evenly with the exception for the "high school equivalent"
category which has a lot more men. 

```{r}
age_dist_by_sex = 
  accel_comb |> 
  distinct(seqn, .keep_all = TRUE) |>
  group_by(education, sex) |> 
  ggplot(aes(x = age, fill = sex)) +
  geom_density() +
  facet_grid(~education) + 
  labs(
    x = "Age",
    y = "Frequency"
  ) +
  ggtitle("Age Distribution for Gender Across Education Levels") +
  theme_update(plot.title = element_text(hjust = 0.5)) 
  
age_dist_by_sex
```


Looking at the graph above, for those with the equivalent of a high school 
education, there are similar amounts of female and male participants between
20 and 60 years old, but for the range of 60-80, more female. From the middle
panel, we can see that the gender distribution is fairly similar across all ages.
For those with more than a high school education within the 20-40 age range,
there's much more female participants than male. 


```{r aggregated}
accel_aggregate_df = 
  accel_comb |> 
  group_by(seqn) |> 
  summarize(
    daily_mims = sum(mims_val)
  )

distinct_users = 
  accel_comb |> 
  distinct(seqn, .keep_all = TRUE)
distinct_users = 
  merge(distinct_users, accel_aggregate_df, by = "seqn")

total_mims_dist_plot =
distinct_users |> 
  ggplot(aes(x=age, y = daily_mims, color = sex)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_grid(~education) +
  labs(
    x = "Age",
    y = "Total Daily Activity (MIMS)",
    color = "sex"
  ) +
  ggtitle("Comparing Daily Activity Against Age Across Sex and Education Level") +
  theme_update(plot.title = element_text(hjust = 0.5))

total_mims_dist_plot
```

We see that the decline in total daily activity across genders follow similar 
trends, with the most observable differences existing across education levels. 
For example, for participants with a high school equivalent education,
the biggest decline happens in the 40s, whereas for those with less than high 
school, the decline happens in the 60s. Those with more than high school,
don't have as steep of a decrease in activity as the other education levels.


```{r time_course}
time_course = 
  accel_comb |>
  group_by(seqn) |> 
  mutate(
    hour = ceiling(minute/60)
  ) |> 
  group_by(seqn, hour) |> 
  mutate(
    total_hourly_mims = sum(mims_val)
  )

time_course_plot = 
  time_course |> 
  group_by(seqn, hour) |> 
  ggplot(aes(x = hour, y = total_hourly_mims, color = sex)) +
  geom_line(alpha = 0.5) +
  geom_smooth(se = FALSE) +
  facet_grid(~education) +
  labs(x = "Hour", y = "Total MIMS per Hour") +
  ggtitle("24-hour Activity Time Courses Across Sex and Education")
time_course_plot
```

The trend lines across education levels for female vs male participants' hourly
MIMS look similar, but for those with more than a high school education, there
appear to be some observations that have much higher activity levels, with
some maximum values exceeding other education levels by more than 1000 MIMS. 

### Problem 3

#### Loading data
```{r load_citi}
citi_jan2020 = read_csv("data/citibike/Jan 2020 Citi.csv")
citi_jan2024 = read_csv("data/citibike/Jan 2024 Citi.csv")
citi_jul2020 = read_csv("data/citibike/July 2020 Citi.csv")
citi_jul2024 = read_csv("data/citibike/July 2024 Citi.csv")
# Checking for NA values
colSums(is.na(citi_jan2020)>0)
colSums(is.na(citi_jan2024)>0)
colSums(is.na(citi_jul2020)>0)
colSums(is.na(citi_jul2024)>0)
```

#### Combining and cleaning
```{r combining_dfs}
citi_jan2020 = 
  citi_jan2020 |> 
  mutate(time_period = "Jan 2020")
citi_jan2024 = 
  citi_jan2024 |> 
  mutate(time_period = "Jan 2024")
citi_jul2020 = 
  citi_jul2020 |> 
  mutate(time_period = "Jul 2020")
citi_jul2024 = 
  citi_jul2024 |> 
  mutate(time_period = "Jul 2024")

weekday_level = c("Mon", "Tue", "Wed", 
                 "Thu", "Fri", "Sat",
                 "Sun")
citi_combined = 
  rbind(citi_jan2020, citi_jan2024, citi_jul2020, citi_jul2024) |> 
  separate(time_period, c("month", "year"), remove = FALSE) |> 
  mutate(
    weekdays = case_match(
      weekdays,
      "Monday" ~ "Mon",
      "Tuesday" ~ "Tue",
      "Wednesday" ~ "Wed",
      "Thursday" ~ "Thu",
      "Friday" ~ "Fri", 
      "Saturday" ~ "Sat",
      "Sunday" ~ "Sun"),
    weekdays = factor(weekdays, levels = weekday_level),
    rideable_type = as.factor(rideable_type),
    member_casual = as.factor(member_casual)
  )
```

#### Casual vs Member Numbers 
```{r}
member_period_table =
  citi_combined |> 
  group_by(member_casual, time_period) |> 
  summarise(n_obs = n()) |> 
  pivot_wider(
    names_from = "time_period", 
    values_from = "n_obs"
  ) |> 
  knitr::kable()
member_period_table
```

Comparing the number of casual vs member riders across January vs July confirms
what we might expect which is that more people are riding bikes in the summer
month. Notably, from July 2020 to July 2024, we also see a 
**huge, nearly two-fold** increase in both casual and member riders, which makes
sense since bike-riding was extremely popular as both an activity and means of
transportation. 

#### July 2024's 5 most popular starting stations
```{r}
pop_station_0724 = 
  head(
    citi_jul2024 |> 
    group_by(start_station_name) |> 
    summarize(n_obs = n()) |> 
    arrange(desc(n_obs))
  , 5) |> 
  knitr::kable()
pop_station_0724
```
The most popular starting stations are in downtown Manhattan.

#### Median ride duration
Make a plot to investigate the effects of day of the week, month, and year on median ride duration. This plot can include one or more panels, but should facilitate comparison across all variables of interest. Comment on your observations from this plot.
```{r median_rides}
median_duration_by_weekday =
  citi_combined |> 
  group_by(weekdays, month, year) |> 
  summarise(
  median_ride_duration = median(duration)) |> 
  ggplot(aes(x = weekdays, y = median_ride_duration, fill = month)) +
  geom_col(position = "dodge2") +
  facet_grid(~year)
median_duration_by_weekday
```

Surprisingly, median ride durations were higher for 2020, and comparing across
months, July was higher. This might make sense though because with the COVID
pandemic, bike-riding may have been an outdoor activity for people to do to 
relieve stress and get outside. For 2024 as well, we see July has
higher medians, and that's justified by people being more likely to ride
outdoor bikes when it's not freezing outside. Expectedly, we also see that the 
rides are longer for Saturday and Sundays which makes sense because during the
weekends, people have more time. 

#### 2024 Information
```{r 2024}
citi2024 = 
  citi_combined |> 
  filter(year == "2024") 

citi_2024_plot = 
  citi2024 |>
  ggplot(aes(x = rideable_type, y = duration)) +
  geom_violin(aes(fill = member_casual)) +
  facet_grid(~month) 
citi_2024_plot
```

Looking at the above graph, the violin plots seem similar to each other, with 
the exception of the electric bikes in January which have smaller ride duration
times. This might be because it's more dangerous to ride e-bikes when it's
colder and more slippery. Across membership status, CITI members have a more
distinctly right-skewed distribution for duration,  




